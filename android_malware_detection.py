from sklearn.feature_selection import mutual_info_classif
import csv
import numpy as np
import random
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC, LinearSVC

class android(object):
	def __init__(self):
		self.split_ratio = 0.7
		ds = open('datasetcl.csv')
		rdr = csv.reader(ds)
		self.data = list(rdr)
		self.data = random.sample(self.data, len(self.data))
		self.data = np.array(self.data)
		ds.close()

	def split(self):
		cols = np.shape(self.data)[1]
		self.X = self.data[:,:cols-1]
		self.X = self.X.astype(np.float)
		self.y = self.data[:,cols-1]
		self.y = np.array(self.y)
		self.y = self.y.astype(np.int)
		y = np.ravel(self.y,order='C')

	def topFeatureList(self):
		features = [i.strip() for i in open("features.txt").readlines()]
		features = np.array(features)
		mi = mutual_info_classif(self.X,self.y)
		self.featureind = sorted(range(len(mi)), key=lambda i: mi[i], reverse=True)[:25]
		top25 = features[self.featureind]

	def splitDs(self):
		splitRows = int(self.split_ratio*len(self.data))
		trainData = self.X[:splitRows,self.featureind]
		trainTarget = self.y[:splitRows]
		testData = self.X[splitRows:,self.featureind]
		testTarget = self.y[splitRows:]
		return trainData, trainTarget, testData, testTarget		

	def Bayes(self):
		#training bayesian classifier
		clf = GaussianNB()
		trainData, trainTarget, testData, testTarget = self.splitDs()
		clf.fit(trainData,trainTarget)
		nbaccr = (clf.score(testData,testTarget))*100
		print nbaccr

	def SVM(self):
		clf = SVC()
		trainData, trainTarget, testData, testTarget = self.splitDs()
		clf.fit(trainData,trainTarget)
		svmaccr = (clf.score(testData,testTarget))*100
		print svmaccr


adr = android()
adr.split()
adr.topFeatureList()
adr.Bayes()
adr.SVM()